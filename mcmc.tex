% to-do
% -----
% - write zeroth draft
% - write first draft
% - send to friendlies for comments
%   - Brewer
%   - Lang
%   - Rix
%   - Bovy
% - post on arXiv

% style notes
% -----------
% - [LaTeX] newline after every full stop for proper git diffing
% - [LaTeX] eqnarray not equation
% - pdf not PDF

\documentclass[12pt,twoside,pdftex]{article}
\usepackage{styles/dar_endnotes}

\newcommand{\this}{Using Markov Chain Monte Carlo}
\include{styles/dar}

\newcommand{\data}{D}
\newcommand{\pars}{\theta}

\begin{document}

\thispagestyle{plain}\raggedbottom
\section*{Data analysis recipes:\\ \this\footnotemark}

\footnotetext{%
    The notes begin on page~\pageref{note:first}, including the
    license\note{\label{note:first}
        Copyright 2013 by the authors. This work is licensed under a
        \href{http://creativecommons.org/licenses/by-nc-nd/3.0/deed.en\_US}{%
            Creative Commons Attribution-NonCommercial-NoDerivs 3.0 Unported
            License}.}
    and the acknowledgements\note{%
        We would like to thank
          Jo Bovy (IAS),
          Brendon Brewer (Auckland),
          Jonathan Goodman (NYU),
          Fengji Hou (NYU), and
          Dustin Lang (CMU)
        for valuable advice and comments.}.
}

\noindent
Dan~Foreman-Mackey\\
\affil{Center~for~Cosmology~and~Particle~Physics, Department~of~Physics,%
       New York University}
\\[1ex]
David~W.~Hogg\\
\affil{Center~for~Cosmology~and~Particle~Physics, Department~of~Physics,%
       New York University}\\
\affil{Max-Planck-Institut f\"ur Astronomie, Heidelberg}

\begin{abstract}
Markov Chain Monte Carlo (MCMC) methods for sampling probability
distribution functions, plus abundant computational resources,
have transformed
the sciences.
Here we give a fast overview of basic MCMC methods and then turn to
practical advice for their use in real inference problems.
We give advice on method choice, tuning for performance,
initialization and burn-in, judging convergence, and use of the chain
output to make results {\it with error bars}.
% ******* BJB
% Do you mean errorbars on the parameters or errorbars
% on posterior quantities as a result of having used a Monte
% Carlo method? The former is much more useful and introductiony
[Insert some generally useful point here!]
\end{abstract}

\section{When do you need MCMC?}

Markov Chain Monte Carlo (MCMC) methods are methods for sampling
probability distribution functions (pdfs). These pdfs may be either probability
mass functions on a discrete space, or probability densities on a continuous
space.
% ******* BJB
% pdf usually stands for probability density function. You are using non-standard
% terminology here. My words above might be too technical given the aim of your
% document.
They don't require that you have a full analytic description of the
properly normalized pdf for sampling to proceed; they only require
that you be able to compute ratios of the pdf at pairs of locations.
These properties make MCMC methods ideal for sampling \emph{posterior
  pdfs} in probabilistic inferences:
% ******** BJB
% I know you don't like it, but LOTS of people use and understand the word
% Bayesian.
In probabilistic inferences, the posterior pdf $p(\pars\given\data)$,
or pdf for the parameters $\pars$ given the data $\data$, is
constructed from the likelihood $p(\data\given\pars)$, or pdf for the
data given the parameters, and the prior pdf $p(\pars)$ for the
parameters by what's often known as ``Bayes rule'',
\begin{eqnarray}
p(\pars\given\data) &=& \frac{1}{Z}\,p(\data\given\pars)\,p(\pars)
\quad .
\end{eqnarray}
% ********* BJB
% Unfortunately there are many more names for the evidence. I prefer
% marginal likelihood myself.
In these contexts, the constant $Z$, sometimes written as
$p(\data)$, is known by the names ``evidence'', ``marginal likelihood''
the ``Bayes integral'' and ``prior predictive probability'', and is usually
\emph{extremely hard to
  calculate}.\note{Say words about why we call it $Z$ not $p(\data)$
  and why it is extremely hard to calculate.}
That is, you often know the function $p(\pars\given\data)$ up to a
constant factor; you can compute ratios of the pdf at pairs of points,
but not the precise value at any individual point.

In addition to this normalization-insensitive property of MCMC, in its
simplest forms it can be run without computing any derivatives or
integrals of the function, and (as we will show below) in its simplest
forms it is \emph{extremely easy to implement}.
For all these reasons, MCMC is ideal for sampling posterior pdfs in
the real situations in which scientists find themselves.

Say you are in this situation.
You have a huge blob of data $\data$ (think of this as a vector or
list or heterogeneous collection of observations\note{In general in
  this \documentname\ we will treat any variable as being capable of
  containing not just a value but some huge arbitrarily structured set
  of values in matrix, vector, or more complex form.}).
You also have a model sophisticated enough---a probabilistic,
generative model, if you will\note{For our definition of a
  \emph{model}, see [SOME OTHER NOTE] in this series.}---that, given a
setting of a huge blob of parameters $\pars$\note{Again, the parameter
  blob $\pars$ should also be thought of as an immense, arbitrarily
  structured set or list of parameters, possibly even with no fixed
  dimension!}, you can compute a pdf for data (or likelihood\note{We
  bash the terminology ``likelihood'' in [SOME OTHER NOTE] in this
  series.}) $p(\data\given\pars)$.
% ************* BJB
% <Wild Subjective Bayesian>
% The "generative model" is a probabilistic description of your *prior
% beliefs about what the data are going to be*. </Wild Subjective Bayesian>
And say you also can write down some kind of informative or
vague prior pdf $p(\pars)$ for the parameter blob.
% ************* BJB
% Uninformative should be banished! The correct word is vague :). Attempts
% at finding formal uninformative priors are misguided IMHO.
If all these things are true, then---even if you can't compute
anything else---in principle a trivial-to-implement MCMC can give you
a fair sampling of the posterior pdf.
That is, you can run MCMC (for a very long time\note{Sometimes a very, very long
  time; we will return to that below.})
% ************* BJB
% It's not always super slow, so added the word "sometimes"
and you will be left with a
set of $K$ parameter-blob settings $\pars_k$ such that the full set
$\setofall{\pars_k}_{k=1}^K$ constitutes a fair sampling from the
posterior pdf $p(\pars\given\data$).
% ************* BJB
% Notions of "sampling" and "Monte Carlo" are interesting. You might like to
% refer the interested reader to the paper "Monte Carlo is Fundamentally
% Unsound" by Tony O'Hagan.

All that said, and adhering to the traditions of the \project{Data
  Analysis Recipes} project\note{Every chapter in the \project{Data
    Analysis Recipes} series begins with a rant in which we argue that
  most uses of the methods in question are not appropriate!}, we are
compelled to note that MCMC is in fact \emph{over-used}.
Because MCMC provably (under assumptions\note{Hint at assumptions
  here.}, some of which will be discussed below) samples the full
posterior pdf in all of parameter space, many investigators use MCMC
because it will sample \emph{all} of the parameter space
($\pars$-space).
That is, they are using MCMC because they want to
\emph{search the parameter space for good models}.
Because MCMC samples the parameter representatively, it spends most of
its time near very good models; models that (within the confines of
the prior pdf) do a good job of explaining the data.
For this reason, many investigators are using MCMC because it
effectively \emph{optimizes the posterior pdf}.

% ********** BJB
% I'm a bit puzzled by this discussion. Most people using MCMC to "optimize"
% are using it on problems where they SHOULD be sampling. Fitting data is almost
% always an inference problem naturally, not an optimization. Optimization is
% more useful for fitting one model to another model.

Both of these reasons for using MCMC---that it is a parameter-space
search algorithm, and that it is a simple-to-code effective
optimizer---are \emph{not good reasons}.  MCMC is first and foremost a
\emph{sampler}.  If you are trying to find the optimum of the
likelihood or the posterior pdf, you should use an \emph{optimzer},
not a sampler.  If you want to make sure you search all of parameter
space, you should use a \emph{search algorithm}, not a sampler.  MCMC
is good at one thing, and one thing only: Sampling ill-normalized
pdfs.

% ********** BJB
% More puzzlement. Most optimizers are degenerate cases of MCMC where
% the target distribution is very concentrated. e.g. M-H becomes an uphill step
% thing, emcee becomes something like the Simplex method, Hamiltonian MCMC
% becomes steepest descent...MCMC and optimization are closely related. You may
% want some discussion of that (but then, it might be too highfalutin).

\section{What is M--H MCMC?}

...The algorithm

...Why does it work (briefly)?

...What is a typical proposal distribution?

...You can't sample the likelihood!  You can only sample a posterior
pdf!
% *********** BJB
% YES!!!! Although you can sample the likelihood if your samples are in
% data space. :)

% *********** BJB
% I suggest partitioning the discussion of different methods into the following
% two categories:
%
%  i) Methods for getting around the target distribution
% ii) Methods that change the target distribution to something
% other than the posterior pdf, to help the sampling somehow
%
% i) Would include things like M-H, the stretch move,
% Hamiltonian, slice sampling (maybe skip the latter)
% ii) would include things like annealing and Nested Sampling


\section{stretch move and other variants}

...How does the stretch move work?

...Why is the stretch move useful?

...What, briefly, is nested sampling, and why is it good?

...What, briefly, is hamiltonian, and why is it good?

\section{Results, error bars, and figures}

...So you have a chain output, what do you do with it?

...What is the number and error bar?  What is an upper limit?
% Do you mean the error bar on the parameter or the error
% bar induced by the sampling?


...What figures should you make to check the chain?

\section{Convergence}

...How do you know you have run long enough?  Heuristically...

...Autocorrelation time

\section{Tuning}

...How do you make it run fast?

...Acceptance ratio and ESJD and etc.

% BJB
% Please suggest mixtures of scales for M-H proposals.
% You can mimic the properties of slice sampling but with
% much easier code.

...Gibbs sampling and interior marginalizations

\section{Initialization and burn-in}

...Precede with optimization
% BJB
% If applicable. Bad idea in high dimension/underconstrained
% problem.

...Start from different locations
% BJB
% What different locations?
% Drawn from the prior can be useful. Then you can
% look at the chains and see which ones "made it" and
% which ones "got stuck" and delete the latter

...Dealing with multi-modal problems
% Starting from different locations is good
% for DIAGNOSING a problem as multimodal but it's
% terrible for quantifying the modes. Explain why,
% it's a good teaching point.

\section{Advice and discussion}

...Write and debug your own M--H sampler and then download a real
package \emph{afterwards}.
% ***** BJB
% I AGREE WHOLEHEARTEDLY. That's how to learn.

...breaking Markov-ness.
% ***** BJB
% "Diminishing adaptations" is an idea that is quite easy
% to explain. There are other ways to break Markov-ness but
% this probably covers enough of them for an intro document

...Initialization and burn-in advice we haven't addressed earlier?

...The Bayes integral / evidence integral?

...Posterior predictive checks?

...Finally, to repeat: You can't sample the likelihood!  You can only
sample a posterior pdf!

% \begin{figure}[htbp]
% \exampleplot{ex17}
% \caption{Partial solution to \problemname~\ref{prob:bayesintrinsic}:
% The marginalized posterior probability distribution for the intrinsic
% variance.}\label{fig:bayesintrinsic}
% \end{figure}

\clearpage
\markright{Notes}\theendnotes

\clearpage
\begin{thebibliography}{}\markright{References}
\bibitem[Foreman-Mackey et al.(2012)]{emcee}
  Foreman-Mackey,~D., Hogg,~D.~W., Lang,~D., \& Goodman,~J.\ 2012,
  \project{emcee}: The MCMC Hammer,
  \arxiv{1202.3665}
\end{thebibliography}

\end{document}
